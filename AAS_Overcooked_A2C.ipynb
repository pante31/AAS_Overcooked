{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S11qsP7bl8Qm"
      },
      "source": [
        "# **_Autonomous and Adaptive Systems_ - 2025**\n",
        "## **Mini-Project**:*Overcooked* - A2C implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Fad_rzpDFx"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-18 10:14:01.471088: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv, Overcooked\n",
        "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
        "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer\n",
        "from overcooked_ai_py.planning.planners import MediumLevelActionManager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing _Overcooked_ environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `base_mdp` = An MDP grid world based off of the Overcooked game.\n",
        "- `base_env` = An environment wrapper for the OvercookedGridworld Markov Decision Process. The environment keeps track of the current state of the agent, updates it as the agent takes actions, and provides rewards to the agent.\n",
        "- `env`= Similar to gym env."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Evn4sHxIrX4c"
      },
      "outputs": [],
      "source": [
        "base_mdp = OvercookedGridworld.from_layout_name(\"cramped_room\", old_dynamics = True) # or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=400)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are different experimetnal layouts:\n",
        "- ***Cramped Room*** presents low-level coordination challenges: in this shared, confined space it is very easy for the agents to collide.\n",
        "- ***Asymmetric Advantages*** tests whether players can choose high-level strategies that play to their strengths.\n",
        "- ***Coordination Ring***, players must coordinate to travel between the bottom left and top right corners of the layout.\n",
        "- ***Forced Coordination*** removes collision coordination problems, and forces players to develop a high-level joint strategy, since neither player can serve a dish by themselves.\n",
        "- ***Counter Circuit*** involves a non-obvious coordination strategy, where onions are passed over the counter to the pot, rather than being carried around."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Actions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The possible actions are: _up, down, left, right, noop,_ and _\"interact\"_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The action space has dimension: Discrete(6)\n"
          ]
        }
      ],
      "source": [
        "print('The action space has dimension: {}'.format(env.action_space))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Observations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'both_agent_obs': (array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., -2.,  0.,  0.,  0., -1.,\n",
              "          2.,  0.,  0.,  0.,  0.,  1.,  2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
              "          0.,  0., -1., -1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  2.,\n",
              "          1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -2.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
              "          1., -1.,  1.,  2.,  1.]),\n",
              "  array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0., -1., -1.,  0.,  0.,  0.,\n",
              "          1.,  0.,  0.,  0.,  0.,  2.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  1., -2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
              "          0.,  0., -2.,  0.,  0.,  0., -1.,  2.,  0.,  0.,  0.,  0.,  1.,\n",
              "          2.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
              "          0.,  1., -1.,  1.,  2.])),\n",
              " 'overcooked_state': <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState at 0x1108de620>,\n",
              " 'other_agent_env_idx': 0}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "observation = env.reset()\n",
        "action = env.action_space.sample()\n",
        "observation, reward, done, info = env.step((action, action))\n",
        "observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIughLCjrUuR"
      },
      "source": [
        "### Understanding the _Overcooked_ **observations** to apply shaping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `[0:4]` pi_orientation: length 4 one-hot-encoding of direction currently facing\n",
        "- `[4:8]` pi_obj: length 4 one-hot-encoding of object currently being held (all 0s if no object held) (onion|soup|dish|tomato)\n",
        "- `[8:20]` pi_closest_{onion|tomato|dish|soup|serving|empty_counter}: (dx, dy) where dx = x dist to item, dy = y dist to item. (0, 0) if item is currently held\n",
        "- `[20:22]` pi_cloest_soup_n_{onions|tomatoes}: int value for number of this ingredient in closest soup ???\n",
        "- `[22:23]` pi_closest_pot_{j}_exists: {0, 1} depending on whether jth closest pot found. If 0, then all other pot features are 0. Note: can be 0 even if there are more than j pots on layout, if the pot is not reachable by player i\n",
        "- `[23:27]` pi_closest_pot_{j}_{is_empty|is_full|is_cooking|is_ready}: {0, 1} depending on boolean value for jth closest pot\n",
        "- `[27:29]` pi_closest_pot_{j}_{num_onions|num_tomatoes}: int value for number of this ingredient in jth closest pot\n",
        "- `[29:30]` pi_closest_pot_{j}_cook_time: int value for seconds remaining on soup. -1 if no soup is cooking\n",
        "- `[30:32]` pi_closest_pot_{j}: (dx, dy) to jth closest pot from player i location\n",
        "- `[32:36]` pi_wall: length 4 boolean value of whether player i has wall in each direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OvercookedRewardShaping(Overcooked):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def step(self, actions):\n",
        "        observation, base_reward, done, info = super().step(actions)\n",
        "        if base_reward != 0:\n",
        "            print(\"Soup delivered! Voto: {}\".format(base_reward)) # base_reward is 20 if soup is delivered\n",
        "        shaped_reward = base_reward + self._compute_shaping(observation['both_agent_obs'])\n",
        "        return observation, shaped_reward, done, info\n",
        "\n",
        "    def _compute_shaping(self, observations):\n",
        "        shaping = 0\n",
        "        for obs in observations:\n",
        "            holding_vector = obs[4:8]\n",
        "            holding_soup = obs[5:6]\n",
        "            soup_full_cooking_ready = obs[24:27]\n",
        "            soup_empty = obs[23:24]\n",
        "            soup_cooking = obs[25:26]\n",
        "            pot_onions = obs[27:28]\n",
        "            \n",
        "            # Penalty if holding an object\n",
        "            #if holding_vector.any():\n",
        "            #    shaping -= 0.05\n",
        "            # Reward if holding a soup\n",
        "            #if holding_soup.any():\n",
        "            #    shaping += 0.1\n",
        "            # Reward if soup is full/cooking/ready\n",
        "            if soup_cooking.any():\n",
        "                shaping += 0.3\n",
        "            # Reward if onion are putted into the soup\n",
        "            #if soup_empty.any():\n",
        "            # shaping += int(pot_onions)*0.01\n",
        "\n",
        "        return shaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = OvercookedRewardShaping(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing a random episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i_episode in range(1):\n",
        "    observation = env.reset()\n",
        "    \n",
        "    for t in range(100):\n",
        "        action = env.action_space.sample()\n",
        "        state = env.step((action, action))\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Networks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_inputs = 96 # length of the observation array\n",
        "num_actions = 6\n",
        "num_hidden = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### _Actor_ model\n",
        "- **Actor**: This takes as input the _state of our environment_ and returns a _probability value_ for each action in its action space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actor-Critic for Player 1\n",
        "actor = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_actions, activation='softmax')\n",
        "])\n",
        "\n",
        "actor = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(num_actions, activation='softmax')\n",
        "])\n",
        "\n",
        "actor_optimizer = keras.optimizers.Adam(learning_rate=1e-7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### _Critic_ model\n",
        "- **Critic**: This takes as input the _state of our environment_ and returns an estimate of _total rewards_ in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "critic = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "critic = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden//4, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "critic_optimizer = keras.optimizers.Adam(learning_rate=1e-7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sources: \n",
        "- https://medium.com/data-science-in-your-pocket/advantage-actor-critic-a2c-algorithm-in-reinforcement-learning-with-codes-and-examples-using-e810273c0c9e\n",
        "- https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration parameters for the whole setup\n",
        "seed = 42\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "eps = np.finfo(np.float32).eps.item()  # Smallest number such that 1.0 + eps != 1.0\n",
        "max_steps_per_episode = 1000\n",
        "\n",
        "mse_loss = keras.losses.MeanSquaredError()\n",
        "\n",
        "num_episodes = 1\n",
        "n_step_before_update = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <u>Update</u>: After each **episode**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chef1_action_probs_history = []\n",
        "chef1_critic_value_history = []\n",
        "chef2_action_probs_history = []\n",
        "chef2_critic_value_history = []\n",
        "rewards_history = []\n",
        "\n",
        "running_reward = 0\n",
        "\n",
        "#while True:  # Run until solved\n",
        "for episode in tqdm(range(num_episodes)):\n",
        "    observation = env.reset() #observation of the starting state\n",
        "    episode_reward = 0\n",
        "    \n",
        "    with tf.GradientTape(persistent = True) as tape:\n",
        "        while True:\n",
        "\n",
        "            chef1_observation = observation['both_agent_obs'][0]\n",
        "            chef2_observation = observation['both_agent_obs'][1]\n",
        "\n",
        "            #chef1_observation = keras.ops.convert_to_tensor([chef1_observation])\n",
        "            chef1_observation = keras.ops.convert_to_tensor(chef1_observation)\n",
        "            chef1_observation = keras.ops.expand_dims(chef1_observation, 0)\n",
        "\n",
        "            chef2_observation = keras.ops.convert_to_tensor(chef2_observation)\n",
        "            chef2_observation = keras.ops.expand_dims(chef2_observation, 0)\n",
        "\n",
        "            # Predict action probabilities and estimated future rewards\n",
        "            # from environment state\n",
        "            chef1_action_probs = actor(chef1_observation)\n",
        "            chef1_critic_value = critic(chef1_observation)\n",
        "            chef1_critic_value_history.append(chef1_critic_value[0, 0])\n",
        "\n",
        "            chef2_action_probs = actor(chef2_observation)\n",
        "            chef2_critic_value = critic(chef2_observation)\n",
        "            chef2_critic_value_history.append(chef2_critic_value[0, 0])\n",
        "\n",
        "            # Sample action from action probability distribution\n",
        "            chef1_action = np.random.choice(num_actions, p=np.squeeze(chef1_action_probs))\n",
        "            chef1_action_probs_history.append(keras.ops.log(chef1_action_probs[0, chef1_action]))\n",
        "\n",
        "            chef2_action = np.random.choice(num_actions, p=np.squeeze(chef2_action_probs))\n",
        "            chef2_action_probs_history.append(keras.ops.log(chef2_action_probs[0, chef2_action]))\n",
        "\n",
        "            # Apply the sampled action in our environment\n",
        "            next_observation, reward, done, info = env.step((chef1_action, chef2_action))\n",
        "            rewards_history.append(reward)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Update running reward to check condition for solving\n",
        "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "        # Calculate expected value from rewards\n",
        "        # - At each timestep what was the total reward received after that timestep\n",
        "        # - Rewards in the past are discounted by multiplying them with gamma\n",
        "        # - These are the labels for our critic\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "\n",
        "        for r in rewards_history[::-1]:\n",
        "            discounted_sum = r + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        # Normalize\n",
        "        returns = np.array(returns)\n",
        "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "        returns = returns.tolist()\n",
        "\n",
        "        # Calculating loss values to update the networks - PLAYER 1 #\n",
        "        chef1_history = zip(chef1_action_probs_history, chef1_critic_value_history, returns)\n",
        "        chef1_actor_losses = []\n",
        "        chef1_critic_losses = []\n",
        "\n",
        "        for log_prob, value, ret in chef1_history:\n",
        "            # At this point in history, the critic estimated that we would get a\n",
        "            # total reward = `value` in the future. We took an action with log probability\n",
        "            # of `log_prob` and ended up receiving a total reward = `ret`.\n",
        "            # The actor must be updated so that it predicts an action that leads to\n",
        "            # high rewards (compared to critic's estimate) with high probability.\n",
        "            diff = ret - value\n",
        "            chef1_actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "            # The critic must be updated so that it predicts a better estimate of\n",
        "            # the future rewards.\n",
        "            chef1_critic_losses.append(\n",
        "                mse_loss(keras.ops.expand_dims(value, 0), keras.ops.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Calculating loss values to update the networks - PLAYER 2 #\n",
        "        chef2_history = zip(chef2_action_probs_history, chef2_critic_value_history, returns)\n",
        "        chef2_actor_losses = []\n",
        "        chef2_critic_losses = []\n",
        "\n",
        "        for log_prob, value, ret in chef2_history:\n",
        "            # At this point in history, the critic estimated that we would get a\n",
        "            # total reward = `value` in the future. We took an action with log probability\n",
        "            # of `log_prob` and ended up receiving a total reward = `ret`.\n",
        "            # The actor must be updated so that it predicts an action that leads to\n",
        "            # high rewards (compared to critic's estimate) with high probability.\n",
        "            diff = ret - value\n",
        "            chef2_actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "            # The critic must be updated so that it predicts a better estimate of\n",
        "            # the future rewards.\n",
        "            chef2_critic_losses.append(\n",
        "                mse_loss(keras.ops.expand_dims(value, 0), keras.ops.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Summing up all the losses\n",
        "        actor_loss_value = sum(chef1_actor_losses) + sum(chef2_actor_losses)\n",
        "        critic_loss_value = sum(chef1_critic_losses) + sum(chef2_critic_losses)\n",
        "        \n",
        "    # Backpropagation for both Actor & Critic   \n",
        "    actor_grads = tape.gradient(actor_loss_value, actor.trainable_variables)\n",
        "    critic_grads = tape.gradient(critic_loss_value, critic.trainable_variables)\n",
        "    \n",
        "    actor_optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
        "    critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
        "\n",
        "    # Clear the loss and reward history\n",
        "    chef1_action_probs_history.clear()\n",
        "    chef1_critic_value_history.clear()\n",
        "    chef2_action_probs_history.clear()\n",
        "    chef2_critic_value_history.clear()\n",
        "    rewards_history.clear()\n",
        "        \n",
        "    del tape # remove the reference to the tape and invoke garbage collection\n",
        "\n",
        "    # Log details\n",
        "    if (episode + 1) % 5 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        print(template.format(running_reward, episode+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "50 episodes at the time (learning rate = 5e-7)\n",
        "    - UP --> 1.6-7, soup: 2\n",
        "             2-10.7, soup: 6 \n",
        "    - DOWN --> 0.5-4.5, soup: 3\n",
        "               2-4, soup: 2\n",
        "100 episodes at the time (learning rate = 5e-7)\n",
        "    - UP --> 0.5-6.6, soup: 0\n",
        "             1.5-7.6, soup: 4\n",
        "             1-7.5, soup: 1\n",
        "300 episodes at the time (learning rate = 5e-8)\n",
        "    - DOWN --> 0.5-6.5, soup: 18 \n",
        "300 episodes at the time (learning rate = 5e-9)\n",
        "    - DOWN --> 0.5-6.5, soup: 18 \n",
        "\n",
        "700 episodes - 128 net_dimensions - 1e-4 --> No learning at all\n",
        "700 episodes - 128 net_dimensions - 1e-5 --> No learning at all\n",
        "\n",
        "100 episodes - 64 net_dimensions - 1e-6 --> No learning at all\n",
        "100 episodes - 64 net_dimensions - 1e-7 --> No learning at all\n",
        "\n",
        "100 episodes - 256 net_dimensions - 1e-5 --> No learning at all, it goes to 0\n",
        "180 episodes - 256 net_dimensions - 1e-8 --> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <u>Update</u>: After each **step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [00:52<1:26:15, 52.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 4/100 [03:44<1:29:13, 55.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 1.42 at episode 4 Actor Loss: -0.25 - Critic Loss: 0.04\n",
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 9/100 [07:53<1:15:26, 49.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 2.94 at episode 9 Actor Loss: 0.31 - Critic Loss: 0.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 14/100 [11:47<1:07:07, 46.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.33 at episode 14 Actor Loss: 0.18 - Critic Loss: 0.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 19/100 [15:39<1:03:14, 46.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 4.15 at episode 19 Actor Loss: -0.36 - Critic Loss: 0.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 24/100 [19:24<57:21, 45.29s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.73 at episode 24 Actor Loss: 0.32 - Critic Loss: 0.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 29/100 [23:09<53:16, 45.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.97 at episode 29 Actor Loss: 0.09 - Critic Loss: 0.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 34/100 [26:56<49:46, 45.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 4.07 at episode 34 Actor Loss: -0.29 - Critic Loss: 0.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 39/100 [30:43<46:00, 45.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.69 at episode 39 Actor Loss: -0.37 - Critic Loss: 0.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 44/100 [34:27<41:53, 44.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.40 at episode 44 Actor Loss: -0.13 - Critic Loss: 0.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 47/100 [36:44<39:56, 45.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|████▉     | 49/100 [38:14<38:16, 45.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 5.75 at episode 49 Actor Loss: -0.51 - Critic Loss: 0.09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [42:00<34:34, 45.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 4.96 at episode 54 Actor Loss: -0.10 - Critic Loss: 0.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 59%|█████▉    | 59/100 [45:42<30:46, 45.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 4.20 at episode 59 Actor Loss: -0.16 - Critic Loss: 0.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 64/100 [49:21<26:24, 44.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 4.26 at episode 64 Actor Loss: -0.22 - Critic Loss: 0.06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 69%|██████▉   | 69/100 [52:57<22:27, 43.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.29 at episode 69 Actor Loss: 0.06 - Critic Loss: 0.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 74/100 [56:31<18:27, 42.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.53 at episode 74 Actor Loss: 0.10 - Critic Loss: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 79/100 [1:00:04<14:53, 42.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.79 at episode 79 Actor Loss: -0.37 - Critic Loss: 0.05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 81/100 [1:01:27<13:21, 42.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 84/100 [1:03:36<11:21, 42.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 4.78 at episode 84 Actor Loss: 0.14 - Critic Loss: 0.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 89/100 [1:07:06<07:43, 42.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 3.70 at episode 89 Actor Loss: -0.16 - Critic Loss: 0.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 94/100 [1:10:33<04:09, 41.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 2.86 at episode 94 Actor Loss: 0.10 - Critic Loss: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 99/100 [1:14:01<00:41, 41.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 2.21 at episode 99 Actor Loss: 0.06 - Critic Loss: 0.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [1:14:50<00:00, 44.90s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "running_reward = 0\n",
        "reward_histroy = []\n",
        "\n",
        "actor_optimizer = keras.optimizers.Adam(learning_rate=7e-3)\n",
        "critic_optimizer = keras.optimizers.Adam(learning_rate=7e-3)\n",
        "\n",
        "losses = {'Actor Loss': [], 'Critic Loss': []}\n",
        "\n",
        "#while True:  # Run until solved\n",
        "for episode in tqdm(range(1, num_episodes+1)):\n",
        "    observation = env.reset() #observation of the starting state\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        with tf.GradientTape(persistent = True) as tape:\n",
        "\n",
        "            chef1_observation = observation['both_agent_obs'][0]\n",
        "            chef2_observation = observation['both_agent_obs'][1]\n",
        "\n",
        "            #chef1_observation = keras.ops.convert_to_tensor([chef1_observation])\n",
        "            chef1_observation = tf.convert_to_tensor(chef1_observation, dtype = tf.float32)\n",
        "            chef1_observation = keras.ops.expand_dims(chef1_observation, 0)\n",
        "\n",
        "            chef2_observation = tf.convert_to_tensor(chef2_observation, dtype = tf.float32)\n",
        "            chef2_observation = keras.ops.expand_dims(chef2_observation, 0)\n",
        "\n",
        "            # Predict action probabilities and estimated future rewards\n",
        "            # from environment state (actor & critic networks)\n",
        "            chef1_action_probs = actor(chef1_observation)\n",
        "            chef1_observation_value = critic(chef1_observation)\n",
        "\n",
        "            chef2_action_probs = actor(chef2_observation)\n",
        "            chef2_observation_value = critic(chef2_observation)\n",
        "\n",
        "            # Sample action from action probability distribution\n",
        "            chef1_action_probs_dist = tfp.distributions.Categorical(probs=chef1_action_probs)\n",
        "            chef1_action = chef1_action_probs_dist.sample()\n",
        "            \n",
        "            chef2_action_probs_dist = tfp.distributions.Categorical(probs=chef2_action_probs)\n",
        "            chef2_action = chef2_action_probs_dist.sample()\n",
        "            '''\n",
        "            chef1_action = np.random.choice(num_actions, p=np.squeeze(chef1_action_probs))\n",
        "            chef2_action = np.random.choice(num_actions, p=np.squeeze(chef2_action_probs))\n",
        "            '''\n",
        "\n",
        "            # Apply the sampled action in our environment\n",
        "            next_observation, reward, done, info = env.step((int(chef1_action), int(chef2_action)))\n",
        "            episode_reward += reward\n",
        "            observation = next_observation\n",
        "\n",
        "            # Lets convert to tensor all we need\n",
        "            chef1_next_observation = next_observation['both_agent_obs'][0]\n",
        "            chef2_next_observation = next_observation['both_agent_obs'][1]\n",
        "\n",
        "            chef1_next_observation = tf.convert_to_tensor([chef1_next_observation], dtype = tf.float32)\n",
        "            chef2_next_observation = tf.convert_to_tensor([chef2_next_observation], dtype = tf.float32)\n",
        "            reward = tf.convert_to_tensor([reward], dtype='float32')\n",
        "\n",
        "            # Predict future rewards from environment state\n",
        "            chef1_next_observation_value = critic(chef1_next_observation)\n",
        "            chef2_next_observation_value = critic(chef2_next_observation)\n",
        "\n",
        "            # To compute the loss we need to get rid of the extra dimenion\n",
        "            #chef1_observation_value = tf.squeeze(chef1_observation_value)\n",
        "            #chef2_observation_value = tf.squeeze(chef2_observation_value)\n",
        "\n",
        "            chef1_next_observation_value = tf.squeeze(chef1_next_observation_value)\n",
        "            chef2_next_observation_value = tf.squeeze(chef2_next_observation_value)\n",
        "\n",
        "            # The advantage function\n",
        "            chef1_target = reward + gamma*chef1_next_observation_value*(1-int(done))\n",
        "            chef2_target = reward + gamma*chef2_next_observation_value*(1-int(done))\n",
        "            \n",
        "            chef1_advantage = chef1_target - chef1_observation_value\n",
        "            chef2_advantage = chef2_target - chef2_observation_value\n",
        "            \n",
        "            '''\n",
        "            chef1_delta = reward + gamma*chef1_next_observation_value*(1-int(done)) - chef1_observation_value\n",
        "            chef2_delta = reward + gamma*chef2_next_observation_value*(1-int(done)) - chef2_observation_value\n",
        "            '''\n",
        "\n",
        "            # Critic loss with MSE loss\n",
        "            chef1_critic_loss = mse_loss(chef1_observation_value, chef1_target)\n",
        "            chef2_critic_loss = mse_loss(chef2_observation_value, chef2_target)\n",
        "            critic_loss = (0.5)*chef1_critic_loss + (0.5)*chef2_critic_loss \n",
        "\n",
        "            '''\n",
        "            chef2_critic_loss = 0.5*(chef2_delta**2)\n",
        "            critic_loss = (0.5)*chef1_critic_loss + (0.5)*chef2_critic_loss \n",
        "            '''\n",
        "\n",
        "            # Actor loss\n",
        "            # To compute the log probabilities\n",
        "            chef1_log_probs = chef1_action_probs_dist.log_prob(chef1_action)\n",
        "            chef2_log_probs = chef2_action_probs_dist.log_prob(chef2_action)\n",
        "\n",
        "            chef1_actor_loss = -chef1_log_probs*chef1_advantage\n",
        "            chef2_actor_loss = -chef2_log_probs*chef2_advantage\n",
        "            actor_loss = (0.5)*chef1_actor_loss + (0.5)*chef2_actor_loss\n",
        "\n",
        "        # Backpropagation for both Actor & Critic   \n",
        "        actor_grads = tape.gradient(actor_loss, actor.trainable_variables)\n",
        "        critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
        "        \n",
        "        actor_optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
        "        critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
        "\n",
        "        del tape\n",
        "\n",
        "    # Let collect the reward of this episode\n",
        "    reward_histroy.append(episode_reward)\n",
        "    # Update running reward to check condition for solving\n",
        "    running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "    # Lets save the losses\n",
        "    losses['Actor Loss'].append(actor_loss)\n",
        "    losses['Critic Loss'].append(critic_loss)\n",
        "    \n",
        "    # Log details\n",
        "    if (episode + 1) % 5 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        template2 = \"Actor Loss: {:.2f} - Critic Loss: {:.2f}\"\n",
        "        print(template.format(running_reward, episode), template2.format(tf.squeeze(losses['Actor Loss'][-1]), tf.squeeze(losses['Critic Loss'][-1])))\n",
        "\n",
        "# Plot the reward over the episodes\n",
        "x = [i+1 for i in range(num_episodes)]\n",
        "y = reward_histroy\n",
        "plt.plot(x,y)\n",
        "plt.show\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test for Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered: 0\n"
          ]
        }
      ],
      "source": [
        "import pygame\n",
        "\n",
        "# 1) Initialize Pygame & Visualizer\n",
        "pygame.init()\n",
        "visualizer = StateVisualizer()\n",
        "\n",
        "# 2) Grab your grid and do one dummy render to get a surface\n",
        "grid = base_env.mdp.terrain_mtx\n",
        "_ = env.reset()\n",
        "surf = visualizer.render_state(base_env.state, grid=grid)\n",
        "\n",
        "# 3) Use that surface’s size for your window\n",
        "win_w, win_h = surf.get_size()\n",
        "screen = pygame.display.set_mode((win_w, win_h), pygame.RESIZABLE)\n",
        "clock  = pygame.time.Clock()\n",
        "\n",
        "# 4) Main loop: render each frame & blit into the same window\n",
        "running = True\n",
        "observation = env.reset() #observation of the starting state\n",
        "soup_delivered = 0\n",
        "\n",
        "while running:\n",
        "    for ev in pygame.event.get():\n",
        "        if ev.type == pygame.QUIT:\n",
        "            running = False\n",
        "    \n",
        "    # observation of the environment\n",
        "    chef1_observation = observation['both_agent_obs'][0]\n",
        "    chef2_observation = observation['both_agent_obs'][1]\n",
        "\n",
        "    chef1_observation = keras.ops.convert_to_tensor(chef1_observation)\n",
        "    chef1_observation = keras.ops.expand_dims(chef1_observation, 0)\n",
        "\n",
        "    chef2_observation = keras.ops.convert_to_tensor(chef2_observation)\n",
        "    chef2_observation = keras.ops.expand_dims(chef2_observation, 0)\n",
        "    \n",
        "    # step the environment\n",
        "    chef1_action_probs = actor(chef1_observation)\n",
        "    chef1_action = np.random.choice(num_actions, p=np.squeeze(chef1_action_probs))\n",
        "    \n",
        "    chef2_action_probs = actor(chef2_observation)\n",
        "    chef2_action = np.random.choice(num_actions, p=np.squeeze(chef2_action_probs))\n",
        "\n",
        "    # try to step; if episode is over, catch and reset\n",
        "    try:\n",
        "        # Overcooked wrapper returns (obs_p0, obs_p1, reward, done, info)\n",
        "        observation, reward, done, info = env.step((chef1_action, chef2_action))\n",
        "        if reward > 19:\n",
        "            soup_delivered += 1\n",
        "    except AssertionError:\n",
        "        # base_env.is_done() was True → reset and continue\n",
        "        env.reset()\n",
        "        break\n",
        "\n",
        "    # render the new state\n",
        "    surf = visualizer.render_state(base_env.state, grid=grid)\n",
        "\n",
        "    # draw it\n",
        "    screen.blit(surf, (0, 0))\n",
        "    pygame.display.flip()\n",
        "\n",
        "    clock.tick(15)   # cap at 30 FPS\n",
        "\n",
        "pygame.quit()\n",
        "\n",
        "print(f\"Soup delivered: {soup_delivered}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aas_overcooked",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
