{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S11qsP7bl8Qm"
      },
      "source": [
        "# **_Autonomous and Adaptive Systems_ - 2025**\n",
        "## **Mini-Project**:*Overcooked* - A2C implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5Fad_rzpDFx"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-18 10:31:35.341948: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from tqdm import tqdm\n",
        "from overcooked_ai_py.mdp.overcooked_env import OvercookedEnv, Overcooked\n",
        "from overcooked_ai_py.mdp.overcooked_mdp import OvercookedGridworld\n",
        "from overcooked_ai_py.visualization.state_visualizer import StateVisualizer\n",
        "from overcooked_ai_py.planning.planners import MediumLevelActionManager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing _Overcooked_ environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `base_mdp` = An MDP grid world based off of the Overcooked game.\n",
        "- `base_env` = An environment wrapper for the OvercookedGridworld Markov Decision Process. The environment keeps track of the current state of the agent, updates it as the agent takes actions, and provides rewards to the agent.\n",
        "- `env`= Similar to gym env."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Evn4sHxIrX4c"
      },
      "outputs": [],
      "source": [
        "base_mdp = OvercookedGridworld.from_layout_name(\"cramped_room\", old_dynamics = True) # or other layout\n",
        "base_env = OvercookedEnv.from_mdp(base_mdp, info_level=0, horizon=400)\n",
        "env = Overcooked(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are different experimetnal layouts:\n",
        "- ***Cramped Room*** presents low-level coordination challenges: in this shared, confined space it is very easy for the agents to collide.\n",
        "- ***Asymmetric Advantages*** tests whether players can choose high-level strategies that play to their strengths.\n",
        "- ***Coordination Ring***, players must coordinate to travel between the bottom left and top right corners of the layout.\n",
        "- ***Forced Coordination*** removes collision coordination problems, and forces players to develop a high-level joint strategy, since neither player can serve a dish by themselves.\n",
        "- ***Counter Circuit*** involves a non-obvious coordination strategy, where onions are passed over the counter to the pot, rather than being carried around."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Actions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The possible actions are: _up, down, left, right, noop,_ and _\"interact\"_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The action space has dimension: Discrete(6)\n"
          ]
        }
      ],
      "source": [
        "print('The action space has dimension: {}'.format(env.action_space))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Observations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'both_agent_obs': (array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,\n",
              "          2.,  0.,  0.,  0.,  0.,  2.,  2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0.,  1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  1.,  0.,  0.,  0., -2.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
              "          2.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
              "          0.,  2.,  0.,  1.,  1.]),\n",
              "  array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0., -2.,\n",
              "          2.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
              "          0.,  0.,  0.,  0., -1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
              "          0.,  0., -1.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  2.,\n",
              "          2.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1., -1.,\n",
              "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
              "          1., -2.,  0.,  3.,  1.])),\n",
              " 'overcooked_state': <overcooked_ai_py.mdp.overcooked_mdp.OvercookedState at 0x105167c70>,\n",
              " 'other_agent_env_idx': 1}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "observation = env.reset()\n",
        "action = env.action_space.sample()\n",
        "observation, reward, done, info = env.step((action, action))\n",
        "observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIughLCjrUuR"
      },
      "source": [
        "### Understanding the _Overcooked_ **observations** to apply shaping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `[0:4]` pi_orientation: length 4 one-hot-encoding of direction currently facing\n",
        "- `[4:8]` pi_obj: length 4 one-hot-encoding of object currently being held (all 0s if no object held) (onion|soup|dish|tomato)\n",
        "- `[8:20]` pi_closest_{onion|tomato|dish|soup|serving|empty_counter}: (dx, dy) where dx = x dist to item, dy = y dist to item. (0, 0) if item is currently held\n",
        "- `[20:22]` pi_cloest_soup_n_{onions|tomatoes}: int value for number of this ingredient in closest soup ???\n",
        "- `[22:23]` pi_closest_pot_{j}_exists: {0, 1} depending on whether jth closest pot found. If 0, then all other pot features are 0. Note: can be 0 even if there are more than j pots on layout, if the pot is not reachable by player i\n",
        "- `[23:27]` pi_closest_pot_{j}_{is_empty|is_full|is_cooking|is_ready}: {0, 1} depending on boolean value for jth closest pot\n",
        "- `[27:29]` pi_closest_pot_{j}_{num_onions|num_tomatoes}: int value for number of this ingredient in jth closest pot\n",
        "- `[29:30]` pi_closest_pot_{j}_cook_time: int value for seconds remaining on soup. -1 if no soup is cooking\n",
        "- `[30:32]` pi_closest_pot_{j}: (dx, dy) to jth closest pot from player i location\n",
        "- `[32:36]` pi_wall: length 4 boolean value of whether player i has wall in each direction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class OvercookedRewardShaping(Overcooked):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def step(self, actions):\n",
        "        observation, base_reward, done, info = super().step(actions)\n",
        "        if base_reward != 0:\n",
        "            print(\"Soup delivered! Voto: {}\".format(base_reward)) # base_reward is 20 if soup is delivered\n",
        "        shaped_reward = base_reward + self._compute_shaping(observation['both_agent_obs'])\n",
        "        return observation, shaped_reward, done, info\n",
        "\n",
        "    def _compute_shaping(self, observations):\n",
        "        shaping = 0\n",
        "        for obs in observations:\n",
        "            holding_vector = obs[4:8]\n",
        "            holding_soup = obs[5:6]\n",
        "            soup_full_cooking_ready = obs[24:27]\n",
        "            soup_empty = obs[23:24]\n",
        "            soup_cooking = obs[25:26]\n",
        "            pot_onions = obs[27:28]\n",
        "            \n",
        "            # Penalty if holding an object\n",
        "            #if holding_vector.any():\n",
        "            #    shaping -= 0.05\n",
        "            # Reward if holding a soup\n",
        "            #if holding_soup.any():\n",
        "            #    shaping += 0.1\n",
        "            # Reward if soup is full/cooking/ready\n",
        "            if soup_cooking.any():\n",
        "                shaping += 0.3\n",
        "            # Reward if onion are putted into the soup\n",
        "            #if soup_empty.any():\n",
        "            # shaping += int(pot_onions)*0.01\n",
        "\n",
        "        return shaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = OvercookedRewardShaping(base_env=base_env, featurize_fn=base_env.featurize_state_mdp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Testing a random episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i_episode in range(1):\n",
        "    observation = env.reset()\n",
        "    \n",
        "    for t in range(100):\n",
        "        action = env.action_space.sample()\n",
        "        state = env.step((action, action))\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Networks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_inputs = 96 # length of the observation array\n",
        "num_actions = 6\n",
        "num_hidden = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### _Actor_ model\n",
        "- **Actor**: This takes as input the _state of our environment_ and returns a _probability value_ for each action in its action space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Actor-Critic for Player 1\n",
        "actor = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_actions, activation='softmax')\n",
        "])\n",
        "\n",
        "actor = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(num_actions, activation='softmax')\n",
        "])\n",
        "\n",
        "actor_optimizer = keras.optimizers.Adam(learning_rate=1e-7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### _Critic_ model\n",
        "- **Critic**: This takes as input the _state of our environment_ and returns an estimate of _total rewards_ in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "critic = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "critic = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=(num_inputs,)),\n",
        "    keras.layers.Dense(num_hidden//2, activation='relu'),\n",
        "    keras.layers.Dense(num_hidden//4, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "critic_optimizer = keras.optimizers.Adam(learning_rate=1e-7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sources: \n",
        "- https://medium.com/data-science-in-your-pocket/advantage-actor-critic-a2c-algorithm-in-reinforcement-learning-with-codes-and-examples-using-e810273c0c9e\n",
        "- https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration parameters for the whole setup\n",
        "seed = 42\n",
        "gamma = 0.99  # Discount factor for past rewards\n",
        "eps = np.finfo(np.float32).eps.item()  # Smallest number such that 1.0 + eps != 1.0\n",
        "mse_loss = keras.losses.MeanSquaredError()\n",
        "\n",
        "num_episodes = 10\n",
        "n_step_before_update = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <u>Update</u>: After each **episode** (**_REINFORCE_**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chef1_action_probs_history = []\n",
        "chef1_critic_value_history = []\n",
        "chef2_action_probs_history = []\n",
        "chef2_critic_value_history = []\n",
        "rewards_history = []\n",
        "\n",
        "running_reward = 0\n",
        "\n",
        "#while True:  # Run until solved\n",
        "for episode in tqdm(range(num_episodes)):\n",
        "    observation = env.reset() #observation of the starting state\n",
        "    episode_reward = 0\n",
        "    \n",
        "    with tf.GradientTape(persistent = True) as tape:\n",
        "        while True:\n",
        "\n",
        "            chef1_observation = observation['both_agent_obs'][0]\n",
        "            chef2_observation = observation['both_agent_obs'][1]\n",
        "\n",
        "            #chef1_observation = keras.ops.convert_to_tensor([chef1_observation])\n",
        "            chef1_observation = keras.ops.convert_to_tensor(chef1_observation)\n",
        "            chef1_observation = keras.ops.expand_dims(chef1_observation, 0)\n",
        "\n",
        "            chef2_observation = keras.ops.convert_to_tensor(chef2_observation)\n",
        "            chef2_observation = keras.ops.expand_dims(chef2_observation, 0)\n",
        "\n",
        "            # Predict action probabilities and estimated future rewards\n",
        "            # from environment state\n",
        "            chef1_action_probs = actor(chef1_observation)\n",
        "            chef1_critic_value = critic(chef1_observation)\n",
        "            chef1_critic_value_history.append(chef1_critic_value[0, 0])\n",
        "\n",
        "            chef2_action_probs = actor(chef2_observation)\n",
        "            chef2_critic_value = critic(chef2_observation)\n",
        "            chef2_critic_value_history.append(chef2_critic_value[0, 0])\n",
        "\n",
        "            # Sample action from action probability distribution\n",
        "            chef1_action = np.random.choice(num_actions, p=np.squeeze(chef1_action_probs))\n",
        "            chef1_action_probs_history.append(keras.ops.log(chef1_action_probs[0, chef1_action]))\n",
        "\n",
        "            chef2_action = np.random.choice(num_actions, p=np.squeeze(chef2_action_probs))\n",
        "            chef2_action_probs_history.append(keras.ops.log(chef2_action_probs[0, chef2_action]))\n",
        "\n",
        "            # Apply the sampled action in our environment\n",
        "            next_observation, reward, done, info = env.step((chef1_action, chef2_action))\n",
        "            rewards_history.append(reward)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Update running reward to check condition for solving\n",
        "        running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "        # Calculate expected value from rewards\n",
        "        # - At each timestep what was the total reward received after that timestep\n",
        "        # - Rewards in the past are discounted by multiplying them with gamma\n",
        "        # - These are the labels for our critic\n",
        "        returns = []\n",
        "        discounted_sum = 0\n",
        "\n",
        "        for r in rewards_history[::-1]:\n",
        "            discounted_sum = r + gamma * discounted_sum\n",
        "            returns.insert(0, discounted_sum)\n",
        "\n",
        "        # Normalize\n",
        "        returns = np.array(returns)\n",
        "        returns = (returns - np.mean(returns)) / (np.std(returns) + eps)\n",
        "        returns = returns.tolist()\n",
        "\n",
        "        # Calculating loss values to update the networks - PLAYER 1 #\n",
        "        chef1_history = zip(chef1_action_probs_history, chef1_critic_value_history, returns)\n",
        "        chef1_actor_losses = []\n",
        "        chef1_critic_losses = []\n",
        "\n",
        "        for log_prob, value, ret in chef1_history:\n",
        "            # At this point in history, the critic estimated that we would get a\n",
        "            # total reward = `value` in the future. We took an action with log probability\n",
        "            # of `log_prob` and ended up receiving a total reward = `ret`.\n",
        "            # The actor must be updated so that it predicts an action that leads to\n",
        "            # high rewards (compared to critic's estimate) with high probability.\n",
        "            diff = ret - value\n",
        "            chef1_actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "            # The critic must be updated so that it predicts a better estimate of\n",
        "            # the future rewards.\n",
        "            chef1_critic_losses.append(\n",
        "                mse_loss(keras.ops.expand_dims(value, 0), keras.ops.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Calculating loss values to update the networks - PLAYER 2 #\n",
        "        chef2_history = zip(chef2_action_probs_history, chef2_critic_value_history, returns)\n",
        "        chef2_actor_losses = []\n",
        "        chef2_critic_losses = []\n",
        "\n",
        "        for log_prob, value, ret in chef2_history:\n",
        "            # At this point in history, the critic estimated that we would get a\n",
        "            # total reward = `value` in the future. We took an action with log probability\n",
        "            # of `log_prob` and ended up receiving a total reward = `ret`.\n",
        "            # The actor must be updated so that it predicts an action that leads to\n",
        "            # high rewards (compared to critic's estimate) with high probability.\n",
        "            diff = ret - value\n",
        "            chef2_actor_losses.append(-log_prob * diff)  # actor loss\n",
        "\n",
        "            # The critic must be updated so that it predicts a better estimate of\n",
        "            # the future rewards.\n",
        "            chef2_critic_losses.append(\n",
        "                mse_loss(keras.ops.expand_dims(value, 0), keras.ops.expand_dims(ret, 0))\n",
        "            )\n",
        "\n",
        "        # Summing up all the losses\n",
        "        actor_loss_value = sum(chef1_actor_losses) + sum(chef2_actor_losses)\n",
        "        critic_loss_value = sum(chef1_critic_losses) + sum(chef2_critic_losses)\n",
        "        \n",
        "    # Backpropagation for both Actor & Critic   \n",
        "    actor_grads = tape.gradient(actor_loss_value, actor.trainable_variables)\n",
        "    critic_grads = tape.gradient(critic_loss_value, critic.trainable_variables)\n",
        "    \n",
        "    actor_optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
        "    critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
        "\n",
        "    # Clear the loss and reward history\n",
        "    chef1_action_probs_history.clear()\n",
        "    chef1_critic_value_history.clear()\n",
        "    chef2_action_probs_history.clear()\n",
        "    chef2_critic_value_history.clear()\n",
        "    rewards_history.clear()\n",
        "        \n",
        "    del tape # remove the reference to the tape and invoke garbage collection\n",
        "\n",
        "    # Log details\n",
        "    if (episode + 1) % 5 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        print(template.format(running_reward, episode+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "50 episodes at the time (learning rate = 5e-7)\n",
        "    - UP --> 1.6-7, soup: 2\n",
        "             2-10.7, soup: 6 \n",
        "    - DOWN --> 0.5-4.5, soup: 3\n",
        "               2-4, soup: 2\n",
        "100 episodes at the time (learning rate = 5e-7)\n",
        "    - UP --> 0.5-6.6, soup: 0\n",
        "             1.5-7.6, soup: 4\n",
        "             1-7.5, soup: 1\n",
        "300 episodes at the time (learning rate = 5e-8)\n",
        "    - DOWN --> 0.5-6.5, soup: 18 \n",
        "300 episodes at the time (learning rate = 5e-9)\n",
        "    - DOWN --> 0.5-6.5, soup: 18 \n",
        "\n",
        "700 episodes - 128 net_dimensions - 1e-4 --> No learning at all\n",
        "700 episodes - 128 net_dimensions - 1e-5 --> No learning at all\n",
        "\n",
        "100 episodes - 64 net_dimensions - 1e-6 --> No learning at all\n",
        "100 episodes - 64 net_dimensions - 1e-7 --> No learning at all\n",
        "\n",
        "100 episodes - 256 net_dimensions - 1e-5 --> No learning at all, it goes to 0\n",
        "180 episodes - 256 net_dimensions - 1e-8 --> \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <u>Update</u>: After each **step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 4/10 [03:26<05:10, 51.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 1.49 at episode 4 Actor Loss: -0.16 - Critic Loss: 0.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 9/10 [08:12<00:57, 57.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running reward: 1.62 at episode 9 Actor Loss: -0.09 - Critic Loss: 0.01\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [09:08<00:00, 54.84s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "running_reward = 0\n",
        "reward_histroy = []\n",
        "\n",
        "actor_optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "critic_optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "losses = {'Actor Loss': [], 'Critic Loss': []}\n",
        "\n",
        "#while True:  # Run until solved\n",
        "for episode in tqdm(range(1, num_episodes+1)):\n",
        "    observation = env.reset() #observation of the starting state\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        with tf.GradientTape(persistent = True) as tape:\n",
        "\n",
        "            chef1_observation = observation['both_agent_obs'][0]\n",
        "            chef2_observation = observation['both_agent_obs'][1]\n",
        "\n",
        "            #chef1_observation = keras.ops.convert_to_tensor([chef1_observation])\n",
        "            chef1_observation = tf.convert_to_tensor(chef1_observation, dtype = tf.float32)\n",
        "            chef1_observation = keras.ops.expand_dims(chef1_observation, 0)\n",
        "\n",
        "            chef2_observation = tf.convert_to_tensor(chef2_observation, dtype = tf.float32)\n",
        "            chef2_observation = keras.ops.expand_dims(chef2_observation, 0)\n",
        "\n",
        "            # Predict action probabilities and estimate future rewards\n",
        "            # from environment state (actor & critic networks)\n",
        "            chef1_action_probs = actor(chef1_observation)\n",
        "            chef1_observation_value = critic(chef1_observation)\n",
        "\n",
        "            chef2_action_probs = actor(chef2_observation)\n",
        "            chef2_observation_value = critic(chef2_observation)\n",
        "\n",
        "            # Sample action from action probability distribution\n",
        "            chef1_action_probs_dist = tfp.distributions.Categorical(probs=chef1_action_probs)\n",
        "            chef1_action = chef1_action_probs_dist.sample()\n",
        "\n",
        "            chef2_action_probs_dist = tfp.distributions.Categorical(probs=chef2_action_probs)\n",
        "            chef2_action = chef2_action_probs_dist.sample()\n",
        "            \n",
        "            '''\n",
        "            chef1_action = np.random.choice(num_actions, p=np.squeeze(chef1_action_probs))\n",
        "            chef2_action = np.random.choice(num_actions, p=np.squeeze(chef2_action_probs))\n",
        "            '''\n",
        "\n",
        "            # Apply the sampled action in our environment\n",
        "            next_observation, reward, done, info = env.step((int(chef1_action), int(chef2_action)))\n",
        "            episode_reward += reward\n",
        "            observation = next_observation\n",
        "\n",
        "            # Lets convert to tensor all we need\n",
        "            chef1_next_observation = next_observation['both_agent_obs'][0]\n",
        "            chef2_next_observation = next_observation['both_agent_obs'][1]\n",
        "\n",
        "            chef1_next_observation = tf.convert_to_tensor([chef1_next_observation], dtype = tf.float32)\n",
        "            chef2_next_observation = tf.convert_to_tensor([chef2_next_observation], dtype = tf.float32)\n",
        "            reward = tf.convert_to_tensor([reward], dtype='float32')\n",
        "\n",
        "            # Predict future rewards from environment state\n",
        "            chef1_next_observation_value = critic(chef1_next_observation)\n",
        "            chef2_next_observation_value = critic(chef2_next_observation)\n",
        "\n",
        "            # To compute the loss we need to get rid of the extra dimenion\n",
        "            #chef1_observation_value = tf.squeeze(chef1_observation_value)\n",
        "            #chef2_observation_value = tf.squeeze(chef2_observation_value)\n",
        "\n",
        "            chef1_next_observation_value = tf.squeeze(chef1_next_observation_value)\n",
        "            chef2_next_observation_value = tf.squeeze(chef2_next_observation_value)\n",
        "\n",
        "            # The advantage function\n",
        "            chef1_target = reward + gamma*chef1_next_observation_value*(1-int(done))\n",
        "            chef2_target = reward + gamma*chef2_next_observation_value*(1-int(done))\n",
        "            \n",
        "            chef1_advantage = chef1_target - chef1_observation_value\n",
        "            chef2_advantage = chef2_target - chef2_observation_value\n",
        "            \n",
        "            '''\n",
        "            chef1_delta = reward + gamma*chef1_next_observation_value*(1-int(done)) - chef1_observation_value\n",
        "            chef2_delta = reward + gamma*chef2_next_observation_value*(1-int(done)) - chef2_observation_value\n",
        "            '''\n",
        "\n",
        "            # Critic loss with MSE loss (==chef_advantage**2)\n",
        "            chef1_critic_loss = mse_loss(chef1_observation_value, chef1_target)\n",
        "            chef2_critic_loss = mse_loss(chef2_observation_value, chef2_target)\n",
        "            '''\n",
        "            chef1_critic_loss = (chef1_advantage**2)\n",
        "            chef2_critic_loss = (chef2_advantage**2)\n",
        "            '''\n",
        "            critic_loss = (0.5)*chef1_critic_loss + (0.5)*chef2_critic_loss \n",
        "\n",
        "            \n",
        "            # Actor loss\n",
        "            # To compute the log probabilities\n",
        "            chef1_log_prob = chef1_action_probs_dist.log_prob(chef1_action)\n",
        "            chef2_log_prob = chef2_action_probs_dist.log_prob(chef2_action)\n",
        "\n",
        "            chef1_actor_loss = -chef1_log_prob*chef1_advantage\n",
        "            chef2_actor_loss = -chef2_log_prob*chef2_advantage\n",
        "            actor_loss = (0.5)*chef1_actor_loss + (0.5)*chef2_actor_loss\n",
        "\n",
        "        # Backpropagation for both Actor & Critic   \n",
        "        actor_grads = tape.gradient(actor_loss, actor.trainable_variables)\n",
        "        critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
        "        \n",
        "        actor_optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
        "        critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
        "\n",
        "        del tape\n",
        "\n",
        "    # Let collect the reward of this episode\n",
        "    reward_histroy.append(episode_reward)\n",
        "    # Update running reward to check condition for solving\n",
        "    running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "    # Lets save the losses - We are just saving the last one, not all the losses through out the episode\n",
        "    losses['Actor Loss'].append(actor_loss)\n",
        "    losses['Critic Loss'].append(critic_loss)\n",
        "    \n",
        "    # Log details\n",
        "    if (episode + 1) % 5 == 0:\n",
        "        template = \"running reward: {:.2f} at episode {}\"\n",
        "        template2 = \"Actor Loss: {:.2f} - Critic Loss: {:.2f}\"\n",
        "        print(template.format(running_reward, episode), template2.format(tf.squeeze(losses['Actor Loss'][-1]), tf.squeeze(losses['Critic Loss'][-1])))\n",
        "\n",
        "# Plot the reward over the episodes\n",
        "x = [i+1 for i in range(num_episodes)]\n",
        "y = reward_histroy\n",
        "plt.plot(x,y)\n",
        "plt.show\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### <u>Update</u>: After each **n-step**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 32  # Number of steps before update\n",
        "n_step_return = 5  # N-step returns for better advantage estimation\n",
        "\n",
        "# Storage for batch updates\n",
        "experience_buffer = {\n",
        "    'chef1_observations': [],\n",
        "    'chef2_observations': [],\n",
        "    'chef1_actions': [],\n",
        "    'chef2_actions': [],\n",
        "    'rewards': [],\n",
        "    'chef1_values': [],\n",
        "    'chef2_values': [],\n",
        "    'dones': []\n",
        "}\n",
        "\n",
        "def compute_n_step_returns(rewards, values, dones, gamma=0.99, n_steps=5):\n",
        "    \"\"\"Compute n-step returns for better advantage estimation\"\"\"\n",
        "    returns = []\n",
        "    for i in range(len(rewards)):\n",
        "        n_step_return = 0\n",
        "        for j in range(min(n_steps, len(rewards) - i)):\n",
        "            if dones[i + j]:\n",
        "                n_step_return += (gamma ** j) * rewards[i + j]\n",
        "                break\n",
        "            n_step_return += (gamma ** j) * rewards[i + j]\n",
        "        \n",
        "        # Add discounted next value if episode didn't end\n",
        "        if i + n_steps < len(rewards) and not any(dones[i:i+n_steps]):\n",
        "            n_step_return += (gamma ** n_steps) * values[i + n_steps]\n",
        "        \n",
        "        returns.append(n_step_return)\n",
        "    \n",
        "    return returns\n",
        "\n",
        "def update_networks(experience_buffer, actor, critic, actor_optimizer, critic_optimizer):\n",
        "    \"\"\"Update networks using batch of experiences\"\"\"\n",
        "    \n",
        "    # Convert lists to tensors\n",
        "    chef1_obs = tf.stack(experience_buffer['chef1_observations'])\n",
        "    chef2_obs = tf.stack(experience_buffer['chef2_observations'])\n",
        "    chef1_actions = tf.stack(experience_buffer['chef1_actions'])\n",
        "    chef2_actions = tf.stack(experience_buffer['chef2_actions'])\n",
        "    rewards = tf.stack(experience_buffer['rewards'])\n",
        "    chef1_values = tf.stack(experience_buffer['chef1_values'])\n",
        "    chef2_values = tf.stack(experience_buffer['chef2_values'])\n",
        "    dones = tf.stack(experience_buffer['dones'])\n",
        "    \n",
        "    # Compute n-step returns\n",
        "    chef1_returns = compute_n_step_returns(\n",
        "        experience_buffer['rewards'], \n",
        "        experience_buffer['chef1_values'], \n",
        "        experience_buffer['dones']\n",
        "    )\n",
        "    chef2_returns = compute_n_step_returns(\n",
        "        experience_buffer['rewards'], \n",
        "        experience_buffer['chef2_values'], \n",
        "        experience_buffer['dones']\n",
        "    )\n",
        "    \n",
        "    chef1_returns = tf.convert_to_tensor(chef1_returns, dtype=tf.float32)\n",
        "    chef2_returns = tf.convert_to_tensor(chef2_returns, dtype=tf.float32)\n",
        "    \n",
        "    # Compute advantages\n",
        "    chef1_advantages = chef1_returns - tf.squeeze(chef1_values)\n",
        "    chef2_advantages = chef2_returns - tf.squeeze(chef2_values)\n",
        "    \n",
        "    # Normalize advantages (optional but often helpful)\n",
        "    chef1_advantages = (chef1_advantages - tf.reduce_mean(chef1_advantages)) / (tf.math.reduce_std(chef1_advantages) + 1e-8)\n",
        "    chef2_advantages = (chef2_advantages - tf.reduce_mean(chef2_advantages)) / (tf.math.reduce_std(chef2_advantages) + 1e-8)\n",
        "    \n",
        "    with tf.GradientTape() as actor_tape, tf.GradientTape() as critic_tape:\n",
        "        # Forward pass\n",
        "        chef1_action_probs = actor(chef1_obs)\n",
        "        chef2_action_probs = actor(chef2_obs)\n",
        "        chef1_predicted_values = critic(chef1_obs)\n",
        "        chef2_predicted_values = critic(chef2_obs)\n",
        "        \n",
        "        # Actor loss\n",
        "        chef1_action_dist = tfp.distributions.Categorical(probs=chef1_action_probs)\n",
        "        chef2_action_dist = tfp.distributions.Categorical(probs=chef2_action_probs)\n",
        "        \n",
        "        chef1_log_probs = chef1_action_dist.log_prob(chef1_actions)\n",
        "        chef2_log_probs = chef2_action_dist.log_prob(chef2_actions)\n",
        "        \n",
        "        # Policy gradient loss\n",
        "        chef1_actor_loss = -tf.reduce_mean(chef1_log_probs * chef1_advantages)\n",
        "        chef2_actor_loss = -tf.reduce_mean(chef2_log_probs * chef2_advantages)\n",
        "        \n",
        "        # Add entropy bonus to encourage exploration\n",
        "        chef1_entropy = -tf.reduce_mean(chef1_action_dist.entropy())\n",
        "        chef2_entropy = -tf.reduce_mean(chef2_action_dist.entropy())\n",
        "        entropy_bonus = 0.01  # Hyperparameter\n",
        "        \n",
        "        actor_loss = 0.5 * (chef1_actor_loss + chef2_actor_loss) + entropy_bonus * (chef1_entropy + chef2_entropy)\n",
        "        \n",
        "        # Critic loss\n",
        "        chef1_critic_loss = tf.reduce_mean(tf.square(chef1_returns - tf.squeeze(chef1_predicted_values)))\n",
        "        chef2_critic_loss = tf.reduce_mean(tf.square(chef2_returns - tf.squeeze(chef2_predicted_values)))\n",
        "        critic_loss = 0.5 * (chef1_critic_loss + chef2_critic_loss)\n",
        "    \n",
        "    # Update networks\n",
        "    actor_grads = actor_tape.gradient(actor_loss, actor.trainable_variables)\n",
        "    critic_grads = critic_tape.gradient(critic_loss, critic.trainable_variables)\n",
        "    \n",
        "    # Clip gradients to prevent exploding gradients\n",
        "    actor_grads = [tf.clip_by_norm(grad, 0.5) for grad in actor_grads]\n",
        "    critic_grads = [tf.clip_by_norm(grad, 0.5) for grad in critic_grads]\n",
        "    \n",
        "    actor_optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
        "    critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
        "    \n",
        "    return actor_loss, critic_loss\n",
        "\n",
        "# Modified training loop\n",
        "running_reward = 0\n",
        "reward_history = []\n",
        "losses = {'Actor Loss': [], 'Critic Loss': []}\n",
        "\n",
        "for episode in tqdm(range(1, num_episodes + 1)):\n",
        "    observation = env.reset()\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    step_count = 0\n",
        "    \n",
        "    while not done:\n",
        "        # Get observations\n",
        "        chef1_obs = tf.convert_to_tensor([observation['both_agent_obs'][0]], dtype=tf.float32)\n",
        "        chef2_obs = tf.convert_to_tensor([observation['both_agent_obs'][1]], dtype=tf.float32)\n",
        "        \n",
        "        # Get action probabilities and values\n",
        "        chef1_action_probs = actor(chef1_obs)\n",
        "        chef2_action_probs = actor(chef2_obs)\n",
        "        chef1_value = critic(chef1_obs)\n",
        "        chef2_value = critic(chef2_obs)\n",
        "        \n",
        "        # Sample actions\n",
        "        chef1_action_dist = tfp.distributions.Categorical(probs=chef1_action_probs)\n",
        "        chef2_action_dist = tfp.distributions.Categorical(probs=chef2_action_probs)\n",
        "        chef1_action = chef1_action_dist.sample()\n",
        "        chef2_action = chef2_action_dist.sample()\n",
        "        \n",
        "        # Take action\n",
        "        next_observation, reward, done, info = env.step((int(chef1_action), int(chef2_action)))\n",
        "        episode_reward += reward\n",
        "        \n",
        "        # Store experience\n",
        "        experience_buffer['chef1_observations'].append(tf.squeeze(chef1_obs))\n",
        "        experience_buffer['chef2_observations'].append(tf.squeeze(chef2_obs))\n",
        "        experience_buffer['chef1_actions'].append(chef1_action)\n",
        "        experience_buffer['chef2_actions'].append(chef2_action)\n",
        "        experience_buffer['rewards'].append(reward)\n",
        "        experience_buffer['chef1_values'].append(chef1_value)\n",
        "        experience_buffer['chef2_values'].append(chef2_value)\n",
        "        experience_buffer['dones'].append(done)\n",
        "        \n",
        "        observation = next_observation\n",
        "        step_count += 1\n",
        "        \n",
        "        # Update networks every batch_size steps or at episode end\n",
        "        if len(experience_buffer['rewards']) >= batch_size or done:\n",
        "            actor_loss, critic_loss = update_networks(\n",
        "                experience_buffer, actor, critic, actor_optimizer, critic_optimizer\n",
        "            )\n",
        "            \n",
        "            # Clear buffer\n",
        "            for key in experience_buffer:\n",
        "                experience_buffer[key] = []\n",
        "            \n",
        "            # Store losses\n",
        "            losses['Actor Loss'].append(actor_loss)\n",
        "            losses['Critic Loss'].append(critic_loss)\n",
        "    \n",
        "    # Episode statistics\n",
        "    reward_history.append(episode_reward)\n",
        "    running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "    \n",
        "    if episode % 5 == 0:\n",
        "        if losses['Actor Loss']:  # Check if we have losses to report\n",
        "            template = \"Episode {}: running reward: {:.2f}\"\n",
        "            template2 = \"Actor Loss: {:.4f} - Critic Loss: {:.4f}\"\n",
        "            print(template.format(episode, running_reward))\n",
        "            print(template2.format(float(losses['Actor Loss'][-1]), float(losses['Critic Loss'][-1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_episodes = 100\n",
        "step_before_update = 128\n",
        "gamma = 0.99 # discount parameter\n",
        "\n",
        "running_reward = 0\n",
        "reward_histroy = []\n",
        "losses = {'Actor Loss': [], 'Critic Loss': []}\n",
        "\n",
        "actor_optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "critic_optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "# Here we store all the values we need to update\n",
        "replay_buffer = {\n",
        "    'chef1_observations': [],\n",
        "    'chef2_observations': [],\n",
        "    'chef1_actions': [],\n",
        "    'chef2_actions': [],\n",
        "    'rewards': [],\n",
        "    'chef1_next_observation_values': [],\n",
        "    'chef2_next_observation_values': [],\n",
        "    'dones': []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_networks(replay_buffer, actor, critic, actor_optimizer, critic_optimizer):\n",
        "    chef1_observations = tf.stack(replay_buffer['chef1_observations'])\n",
        "    chef2_observations = tf.stack(replay_buffer['chef2_observations'])\n",
        "    chef1_actions = replay_buffer['chef1_actions']\n",
        "    chef2_actions = replay_buffer['chef2_actions']\n",
        "    rewards = replay_buffer['rewards']\n",
        "    chef1_next_observation_values = replay_buffer['chef1_next_observation_values']\n",
        "    chef2_next_observation_values = replay_buffer['chef2_next_observation_values']\n",
        "    dones = replay_buffer['dones']\n",
        "\n",
        "    # Compute the returns for each of the n-step\n",
        "    chef1_returns = []\n",
        "    chef2_returns = []\n",
        "\n",
        "    for i in range(len(rewards)):\n",
        "        n_step_return = 0\n",
        "        for j in range(min(step_before_update, len(rewards) - i)):\n",
        "            if dones[i + j]:\n",
        "                n_step_return += (gamma ** j) * rewards[i + j]\n",
        "                break\n",
        "            n_step_return += (gamma ** j) * rewards[i + j]\n",
        "        \n",
        "        # Add discounted next value if episode didn't end\n",
        "        if i + step_before_update < len(rewards) and not any(dones[i:i+step_before_update]):\n",
        "            chef1_observation_value = critic(chef1_observation[i+step_before_update])\n",
        "            chef1_observation_value = tf.squeeze(chef1_observation_value)\n",
        "            n_step_return += (gamma ** step_before_update) * chef1_observation_value\n",
        "        chef1_returns.append(n_step_return)\n",
        "    \n",
        "    for i in range(len(rewards)):\n",
        "        n_step_return = 0\n",
        "        for j in range(min(step_before_update, len(rewards) - i)):\n",
        "            if dones[i + j]:\n",
        "                n_step_return += (gamma ** j) * rewards[i + j]\n",
        "                break\n",
        "            n_step_return += (gamma ** j) * rewards[i + j]\n",
        "        \n",
        "        # Add discounted next value if episode didn't end\n",
        "        if i + step_before_update < len(rewards) and not any(dones[i:i+step_before_update]):\n",
        "            chef1_observation_value = critic(chef1_observation[i+step_before_update])\n",
        "            chef1_observation_value = tf.squeeze(chef2_observation_value)\n",
        "            n_step_return += (gamma ** step_before_update) * chef2_observation_value\n",
        "        chef2_returns.append(n_step_return)\n",
        "    \n",
        "    chef1_returns = tf.convert_to_tensor(chef1_returns, dtype=tf.float32)\n",
        "    chef2_returns = tf.convert_to_tensor(chef2_returns, dtype=tf.float32)\n",
        "\n",
        "    chef1_advantages = chef1_returns - tf.squeeze(chef1_next_observation_values)\n",
        "    chef2_advantages = chef2_returns - tf.squeeze(chef2_next_observation_values)\n",
        "\n",
        "\n",
        "    with tf.GradientTape(persistent = True) as tape:\n",
        "        # Forward pass\n",
        "        chef1_action_probs = actor(chef1_observations)\n",
        "        chef2_action_probs = actor(chef2_observations)\n",
        "        chef1_predicted_values = critic(chef1_observations)\n",
        "        chef2_predicted_values = critic(chef2_observations)\n",
        "        \n",
        "        # Actor loss\n",
        "        chef1_action_dist = tfp.distributions.Categorical(probs=chef1_action_probs)\n",
        "        chef2_action_dist = tfp.distributions.Categorical(probs=chef2_action_probs)\n",
        "        \n",
        "        chef1_log_probs = chef1_action_dist.log_prob(chef1_actions)\n",
        "        chef2_log_probs = chef2_action_dist.log_prob(chef2_actions)\n",
        "        \n",
        "        # Policy gradient loss\n",
        "        chef1_actor_loss = -tf.reduce_mean(chef1_log_probs * chef1_advantages)\n",
        "        chef2_actor_loss = -tf.reduce_mean(chef2_log_probs * chef2_advantages)\n",
        "        \n",
        "        # Add entropy bonus to encourage exploration\n",
        "        chef1_entropy = -tf.reduce_mean(chef1_action_dist.entropy())\n",
        "        chef2_entropy = -tf.reduce_mean(chef2_action_dist.entropy())\n",
        "        entropy_bonus = 0.01  # Hyperparameter\n",
        "        \n",
        "        actor_loss = 0.5 * (chef1_actor_loss + chef2_actor_loss) + entropy_bonus * (chef1_entropy + chef2_entropy)\n",
        "        \n",
        "        # Critic loss\n",
        "        chef1_critic_loss = tf.reduce_mean(tf.square(chef1_returns - tf.squeeze(chef1_predicted_values)))\n",
        "        chef2_critic_loss = tf.reduce_mean(tf.square(chef2_returns - tf.squeeze(chef2_predicted_values)))\n",
        "        critic_loss = 0.5 * (chef1_critic_loss + chef2_critic_loss) \n",
        "    \n",
        "    # Update networks\n",
        "    actor_grads = tape.gradient(actor_loss, actor.trainable_variables)\n",
        "    critic_grads = tape.gradient(critic_loss, critic.trainable_variables)\n",
        "    \n",
        "    # Clip gradients to prevent exploding gradients\n",
        "    actor_grads = [tf.clip_by_norm(grad, 0.5) for grad in actor_grads]\n",
        "    critic_grads = [tf.clip_by_norm(grad, 0.5) for grad in critic_grads]\n",
        "    \n",
        "    actor_optimizer.apply_gradients(zip(actor_grads, actor.trainable_variables))\n",
        "    critic_optimizer.apply_gradients(zip(critic_grads, critic.trainable_variables))\n",
        "\n",
        "    del tape\n",
        "\n",
        "    return actor_loss, critic_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1/100 [00:16<26:28, 16.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 5/100 [01:30<28:17, 17.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 5: running reward: 2.92\n",
            "Actor Loss: 2.8659 - Critic Loss: 10.1453\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 10/100 [02:58<26:24, 17.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 10: running reward: 3.37\n",
            "Actor Loss: -0.1037 - Critic Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 15/100 [04:25<24:39, 17.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 15: running reward: 3.59\n",
            "Actor Loss: -0.0972 - Critic Loss: 0.0025\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 20/100 [05:50<22:51, 17.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 20: running reward: 4.79\n",
            "Actor Loss: -0.1466 - Critic Loss: 0.0044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 25/100 [07:14<21:00, 16.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 25: running reward: 4.19\n",
            "Actor Loss: -0.1255 - Critic Loss: 0.0034\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 30/100 [08:37<19:08, 16.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 30: running reward: 4.71\n",
            "Actor Loss: -0.1682 - Critic Loss: 0.0070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|███       | 31/100 [08:53<18:46, 16.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 35/100 [09:58<17:33, 16.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 35: running reward: 6.57\n",
            "Actor Loss: -0.1694 - Critic Loss: 0.0071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 38/100 [10:48<16:57, 16.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 40/100 [11:19<16:07, 16.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 40: running reward: 7.66\n",
            "Actor Loss: -0.1293 - Critic Loss: 0.0055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 45/100 [12:39<14:34, 15.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 45: running reward: 5.93\n",
            "Actor Loss: -0.1208 - Critic Loss: 0.0040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 48/100 [13:26<13:44, 15.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 50/100 [13:58<13:10, 15.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 50: running reward: 7.65\n",
            "Actor Loss: -0.1116 - Critic Loss: 0.0031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 54/100 [15:01<12:08, 15.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 55/100 [15:20<12:34, 16.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 55: running reward: 8.96\n",
            "Actor Loss: -0.1433 - Critic Loss: 0.0044\n",
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 60/100 [16:49<11:12, 16.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 60: running reward: 10.79\n",
            "Actor Loss: -0.2548 - Critic Loss: 0.0273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 63/100 [17:37<09:56, 16.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 64/100 [17:52<09:35, 16.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 65/100 [18:08<09:17, 15.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 65: running reward: 12.41\n",
            "Actor Loss: -0.1007 - Critic Loss: 0.0023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 66/100 [18:24<09:01, 15.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n",
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 70/100 [19:30<08:14, 16.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 70: running reward: 13.83\n",
            "Actor Loss: -0.2800 - Critic Loss: 0.0206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 71%|███████   | 71/100 [19:46<07:52, 16.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 74/100 [20:33<06:55, 15.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 75/100 [20:49<06:38, 15.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 75: running reward: 14.62\n",
            "Actor Loss: -0.1426 - Critic Loss: 0.0046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 76/100 [21:08<06:38, 16.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 77/100 [21:24<06:19, 16.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 78/100 [21:40<05:59, 16.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 80/100 [22:13<05:26, 16.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 80: running reward: 16.55\n",
            "Actor Loss: -0.1748 - Critic Loss: 0.0088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 85/100 [23:32<03:58, 15.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 85: running reward: 15.90\n",
            "Actor Loss: -0.2615 - Critic Loss: 0.0241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 90/100 [24:50<02:36, 15.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 90: running reward: 14.88\n",
            "Actor Loss: -0.1892 - Critic Loss: 0.0120\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 93/100 [25:37<01:48, 15.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 94/100 [25:53<01:33, 15.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 95/100 [26:10<01:20, 16.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 95: running reward: 15.20\n",
            "Actor Loss: -0.2613 - Critic Loss: 0.0204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 96/100 [26:25<01:03, 15.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered! Voto: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [27:28<00:00, 16.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 100: running reward: 15.20\n",
            "Actor Loss: -0.2491 - Critic Loss: 0.0201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for episode in tqdm(range(1, num_episodes+1)):\n",
        "    # We initialize the state S\n",
        "    observation = env.reset()\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    timestep = 0\n",
        "    \n",
        "    while not done:\n",
        "        # Each chef has its own observation\n",
        "        chef1_observation = tf.convert_to_tensor(observation['both_agent_obs'][0], dtype = tf.float32)\n",
        "        chef2_observation = tf.convert_to_tensor(observation['both_agent_obs'][1], dtype = tf.float32)\n",
        "        chef1_observation = keras.ops.expand_dims(chef1_observation, 0)\n",
        "        chef2_observation = keras.ops.expand_dims(chef2_observation, 0)\n",
        "\n",
        "        # Action selection & State value - Using ACTOR\n",
        "        # Predict action probabilities from present state\n",
        "        chef1_action_probs = actor(chef1_observation)\n",
        "        chef2_action_probs = actor(chef2_observation)\n",
        "\n",
        "        # Sample action from action probability distribution\n",
        "        chef1_action_prob_dist = tfp.distributions.Categorical(probs=chef1_action_probs)\n",
        "        chef2_action_prob_dist = tfp.distributions.Categorical(probs=chef2_action_probs)\n",
        "        chef1_action = chef1_action_prob_dist.sample()\n",
        "        chef2_action = chef2_action_prob_dist.sample()\n",
        "\n",
        "        # Apply the sampled action in our environment\n",
        "        next_observation, reward, done, info = env.step((int(chef1_action), int(chef2_action)))\n",
        "        episode_reward += reward\n",
        "        \n",
        "        # These are the new observation, after the action just taken\n",
        "        chef1_next_observation = tf.convert_to_tensor([next_observation['both_agent_obs'][0]], dtype = tf.float32)\n",
        "        chef2_next_observation = tf.convert_to_tensor([next_observation['both_agent_obs'][1]], dtype = tf.float32)\n",
        "\n",
        "        # Predict future rewards from environment state\n",
        "        chef1_next_observation_value = critic(chef1_next_observation)\n",
        "        chef2_next_observation_value = critic(chef2_next_observation)\n",
        "        \n",
        "        # Convert reward into a Tensor before loading it inside the buffer\n",
        "        reward = tf.convert_to_tensor([reward], dtype='float32')        \n",
        "        \n",
        "        # Store experience inside the buffer \n",
        "        replay_buffer['chef1_observations'].append(tf.squeeze(chef1_observation))\n",
        "        replay_buffer['chef2_observations'].append(tf.squeeze(chef2_observation))\n",
        "        replay_buffer['chef1_actions'].append(chef1_action)\n",
        "        replay_buffer['chef2_actions'].append(chef2_action)\n",
        "        replay_buffer['rewards'].append(reward)\n",
        "        replay_buffer['chef1_next_observation_values'].append(tf.squeeze(chef1_next_observation_value))\n",
        "        replay_buffer['chef2_next_observation_values'].append(tf.squeeze(chef2_next_observation_value))\n",
        "        replay_buffer['dones'].append(done)\n",
        "\n",
        "        observation = next_observation\n",
        "        timestep += 1\n",
        "\n",
        "        # Update the networks every n-step or at the end of the episode\n",
        "        if len(replay_buffer['rewards']) >= step_before_update or done:\n",
        "            actor_loss, critic_loss = update_networks(replay_buffer, actor, critic, actor_optimizer, critic_optimizer)\n",
        "        \n",
        "            # Clear buffer\n",
        "            for key in replay_buffer:\n",
        "                replay_buffer[key] = []\n",
        "            \n",
        "            # Store losses\n",
        "            losses['Actor Loss'].append(actor_loss)\n",
        "            losses['Critic Loss'].append(critic_loss)\n",
        "\n",
        "    # Let collect the reward of this episode\n",
        "    reward_histroy.append(episode_reward)\n",
        "    # Update running reward to check condition for solving\n",
        "    running_reward = 0.05 * episode_reward + (1 - 0.05) * running_reward\n",
        "\n",
        "    # Log details\n",
        "    if episode % 5 == 0:\n",
        "        template = \"Episode {}: running reward: {:.2f}\"\n",
        "        print(template.format(episode, running_reward))\n",
        "        if losses['Actor Loss']:  # Check if we have losses to report\n",
        "            template2 = \"Actor Loss: {:.4f} - Critic Loss: {:.4f}\"\n",
        "            print(template2.format(float(losses['Actor Loss'][-1]), float(losses['Critic Loss'][-1])))\n",
        "\n",
        "# Plot the reward over the episodes\n",
        "x = [i+1 for i in range(num_episodes)]\n",
        "y = reward_histroy\n",
        "plt.plot(x,y)\n",
        "plt.show\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test for Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soup delivered: 0\n"
          ]
        }
      ],
      "source": [
        "import pygame\n",
        "\n",
        "# 1) Initialize Pygame & Visualizer\n",
        "pygame.init()\n",
        "visualizer = StateVisualizer()\n",
        "\n",
        "# 2) Grab your grid and do one dummy render to get a surface\n",
        "grid = base_env.mdp.terrain_mtx\n",
        "_ = env.reset()\n",
        "surf = visualizer.render_state(base_env.state, grid=grid)\n",
        "\n",
        "# 3) Use that surface’s size for your window\n",
        "win_w, win_h = surf.get_size()\n",
        "screen = pygame.display.set_mode((win_w, win_h), pygame.RESIZABLE)\n",
        "clock  = pygame.time.Clock()\n",
        "\n",
        "# 4) Main loop: render each frame & blit into the same window\n",
        "running = True\n",
        "observation = env.reset() #observation of the starting state\n",
        "soup_delivered = 0\n",
        "\n",
        "while running:\n",
        "    for ev in pygame.event.get():\n",
        "        if ev.type == pygame.QUIT:\n",
        "            running = False\n",
        "    \n",
        "    # observation of the environment\n",
        "    chef1_observation = observation['both_agent_obs'][0]\n",
        "    chef2_observation = observation['both_agent_obs'][1]\n",
        "\n",
        "    chef1_observation = keras.ops.convert_to_tensor(chef1_observation)\n",
        "    chef1_observation = keras.ops.expand_dims(chef1_observation, 0)\n",
        "\n",
        "    chef2_observation = keras.ops.convert_to_tensor(chef2_observation)\n",
        "    chef2_observation = keras.ops.expand_dims(chef2_observation, 0)\n",
        "    \n",
        "    # step the environment\n",
        "    chef1_action_probs = actor(chef1_observation)\n",
        "    chef1_action = np.random.choice(num_actions, p=np.squeeze(chef1_action_probs))\n",
        "    \n",
        "    chef2_action_probs = actor(chef2_observation)\n",
        "    chef2_action = np.random.choice(num_actions, p=np.squeeze(chef2_action_probs))\n",
        "\n",
        "    # try to step; if episode is over, catch and reset\n",
        "    try:\n",
        "        # Overcooked wrapper returns (obs_p0, obs_p1, reward, done, info)\n",
        "        observation, reward, done, info = env.step((chef1_action, chef2_action))\n",
        "        if reward > 19:\n",
        "            soup_delivered += 1\n",
        "    except AssertionError:\n",
        "        # base_env.is_done() was True → reset and continue\n",
        "        env.reset()\n",
        "        break\n",
        "\n",
        "    # render the new state\n",
        "    surf = visualizer.render_state(base_env.state, grid=grid)\n",
        "\n",
        "    # draw it\n",
        "    screen.blit(surf, (0, 0))\n",
        "    pygame.display.flip()\n",
        "\n",
        "    clock.tick(15)   # cap at 30 FPS\n",
        "\n",
        "pygame.quit()\n",
        "\n",
        "print(f\"Soup delivered: {soup_delivered}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aas_overcooked",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
